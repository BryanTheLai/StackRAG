{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d1494fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- User Query ---\n",
      "Whats the Gross Carrying Amount for Total intangible assets for tesla in 2021? Create a report of tesla for 2021 in markdown i can copy.\n",
      "\n",
      "--- Initializing clients and authenticating ---\n",
      "Initialized OpenAI client with model: text-embedding-3-small\n",
      "Initializing Gemini client with API key: AIz...yQ\n",
      "Supabase client created.\n",
      "Attempting to sign in with email: wbryanlai@gmail.com\n",
      "Authentication successful. User ID: e222921f-cfdc-4a05-8cf2-aea13004bcf2\n",
      "SupabaseService initialized with provided client.\n",
      "Clients initialized and authenticated.\n",
      "\n",
      "--- Sending initial query to Gemini (gemini-2.5-flash-preview-04-17) ---\n",
      "  Conversation History before first call:\n",
      "[\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"parts\": [\n",
      "      {\n",
      "        \"text\": \"Whats the Gross Carrying Amount for Total intangible assets for tesla in 2021? Create a report of tesla for 2021 in markdown i can copy.\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "]\n",
      "\n",
      "--- Received response from first Gemini call ---\n",
      "\n",
      "  Model's response content (first call) added to history.\n",
      "\n",
      "--- Gemini requested function call: 'retrieve_financial_chunks' ---\n",
      "  Raw Arguments from LLM: {'doc_year_end': 2021, 'match_count': 5, 'doc_year_start': 2021, 'company_name': 'Tesla', 'query_text': 'Gross Carrying Amount for Total intangible assets'}\n",
      "  Recognized 'retrieve_financial_chunks' call.\n",
      "  Extracted tool_args before adding user_id: {'doc_year_end': 2021, 'match_count': 5, 'doc_year_start': 2021, 'company_name': 'Tesla', 'query_text': 'Gross Carrying Amount for Total intangible assets'}\n",
      "  Tool_args *including* user_id for execution: {'doc_year_end': 2021, 'match_count': 5, 'doc_year_start': 2021, 'company_name': 'Tesla', 'query_text': 'Gross Carrying Amount for Total intangible assets', 'user_id': 'e222921f-cfdc-4a05-8cf2-aea13004bcf2'}\n",
      "\n",
      "--- Executing Tool: retrieve_financial_chunks ---\n",
      "  Query: 'Gross Carrying Amount for Total intangible assets'\n",
      "  User ID: e222921f-cfdc-4a05-8cf2-aea13004bcf2\n",
      "  Filters: Type=None, Company=Tesla, Year=2021-2021, Qtr=None\n",
      "  Query embedding generated.\n",
      "  Calling Supabase RPC 'match_chunks'...\n",
      "  Retrieved 4 chunks from Supabase.\n",
      "  Returning JSON result (8343 chars, first 500 for brevity):\n",
      "[\n",
      "  {\n",
      "    \"id\": \"744c0555-913c-40c4-87e7-33bfc00010f8\",\n",
      "    \"chunk_text\": \"## FORM 10-K\\n\\n(Mark One)\\n\\u2611 ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE\\nACT OF 1934\\n\\nFor the fiscal year ended December 31, 2021\\nOR\\n\\nTRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES\\nEXCHANGE ACT OF 1934\\n\\nFor the transition period from ______ to ______\\nCommission File Number: 001-34756\\n\\nTesla, Inc.\\n(Exact name of registrant as specified in its charter)\\n\\n...\n",
      "\n",
      "--- Finished executing retrieve_financial_chunks ---\n",
      "  Function result (JSON string, first 500 chars):\n",
      "[\n",
      "  {\n",
      "    \"id\": \"744c0555-913c-40c4-87e7-33bfc00010f8\",\n",
      "    \"chunk_text\": \"## FORM 10-K\\n\\n(Mark One)\\n\\u2611 ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE\\nACT OF 1934\\n\\nFor the fiscal year ended December 31, 2021\\nOR\\n\\nTRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES\\nEXCHANGE ACT OF 1934\\n\\nFor the transition period from ______ to ______\\nCommission File Number: 001-34756\\n\\nTesla, Inc.\\n(Exact name of registrant as specified in its charter)\\n\\n...\n",
      "\n",
      "--- Preparing enriched context and instructions for final Gemini call ---\n",
      "  Raw function response part added to history.\n",
      "  Formatted snippets and citation instructions added to history.\n",
      "\n",
      "  Conversation History before second call (final answer generation):\n",
      "[\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"parts\": [\n",
      "      {\n",
      "        \"text\": \"Whats the Gross Carrying Amount for Total intangible assets for tesla in 2021? Create a report of tesla for 2021 in markdown i can copy.\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"model\",\n",
      "    \"parts\": [\n",
      "      {\n",
      "        \"function_call\": {\n",
      "          \"name\": \"retrieve_financial_chunks\",\n",
      "          \"args\": {\n",
      "            \"doc_year_end\": 2021,\n",
      "            \"match_count\": 5,\n",
      "            \"doc_year_start\": 2021,\n",
      "            \"company_name\": \"Tesla\",\n",
      "            \"query_text\": \"Gross Carrying Amount for Total intangible assets\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"parts\": [\n",
      "      {\n",
      "        \"function_response\": {\n",
      "          \"name\": \"retrieve_financial_chunks\",\n",
      "          \"response\": {\n",
      "            \"result\": [\n",
      "              {\n",
      "                \"id\": \"744c0555-913c-40c4-87e7-33bfc00010f8\",\n",
      "                \"chunk_text\": \"## FORM 10-K\\n\\n(Mark One)\\n\\u2611 ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE\\nACT OF 1934\\n\\nFor the fiscal year ended December 31, 2021\\nOR\\n\\nTRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES\\nEXCHANGE ACT OF 1934\\n\\nFor the transition period from ______ to ______\\nCommission File Number: 001-34756\\n\\nTesla, Inc.\\n(Exact name of registrant as specified in its charter)\\n\\nDelaware\\n(State or other jurisdiction of\\nincorporation or organization)\\n\\n91-2197729\\n(I.R.S. Employer\\nIdentification No.)\\n\\n13101 Tesla Road\\nAustin, Texas\\n(Address of principal executive offices)\\n\\n78725\\n(Zip Code)\\n\\n(512) 516-8177\\n(Registrant's telephone number, including area code)\\n\\nSecurities registered pursuant to Section 12(b) of the Act:\\n\\n| Title of each class | Trading Symbol(s) | Name of each exchange on which registered |\\n|---|---|---|\\n| Common stock | TSLA | The Nasdaq Global Select Market |\\n\\nSecurities registered pursuant to Section 12(g) of the Act:\\nNone\\n\\nIndicate by check mark whether the registrant is a well-known seasoned issuer, as defined in Rule 405 of the Securities Act. Yes\\n\\u25a1 No \\u2611\\n\\nIndicate by check mark if the registrant is not required to file reports pursuant to Section 13 or 15(d) of the Act. Yes \\u25a1 No \\u2611\\n\\nIndicate by check mark whether the registrant (1) has filed all reports required to be filed by Section 13 or 15(d) of the Securities\\nExchange Act of 1934 (\\u201cExchange Act\\\") during the preceding 12 months (or for such shorter period that the registrant was required to\\nfile such reports), and (2) has been subject to such filing requirements for the past 90 days. Yes \\u2611 No \\u25a1\\n\\nIndicate by check mark whether the registrant has submitted electronically every Interactive Data File required to be submitted\\npursuant to Rule 405 of Regulation S-T (\\u00a7232.405 of this chapter) during the preceding 12 months (or for such shorter period that the\\nregistrant was required to submit such files). Yes \\u2611 No \\u25a1\\n\\nIndicate by check mark whether the registrant is a large accelerated filer, an accelerated filer, a non-accelerated filer, a smaller\\nreporting company, or an emerging growth company. See the definitions of \\u201clarge accelerated filer,\\\" \\u201caccelerated filer,\\u201d \\u201csmaller\\nreporting company\\\" and \\\"emerging growth company\\\" in Rule 12b-2 of the Exchange Act:\\n\\n\\u2611 Large accelerated filer\\n\\u25a1 Non-accelerated filer\\n\\u25a1 Emerging growth company\\n\\n\\u25a1 Accelerated filer\\n\\u25a1 Smaller reporting company\\n\\nIf an emerging growth company, indicate by check mark if the registrant has elected not to use the extended transition period for\\ncomplying with any new or revised financial accounting standards provided pursuant to Section 13(a) of the Exchange Act. \\u25a1\\n```\\n\\n--- Page 1 End ---\\n\\n\\n\\n--- Page 2 Start ---\\n\\nTESLA, INC.\\n\\nANNUAL REPORT ON FORM 10-K FOR THE YEAR ENDED DECEMBER 31, 2021\\n\\nINDEX\\n\\nPage\\n\\nPART I.\\n\\nItem 1. Business 4\\nItem 1A. Risk Factors 14\\nItem 1B. Unresolved Staff Comments 28\\nItem 2. Properties 28\\nItem 3. Legal Proceedings 28\\nItem 4. Mine Safety Disclosures 28\\n\\nPART II.\\n\\nItem 5. Market for Registrant's Common Equity, Related Stockholder Matters and Issuer Purchases of Equity\\nSecurities 29\\nItem 6. [Reserved] 30\\nItem 7. Management's Discussion and Analysis of Financial Condition and Results of Operations 31\\nItem 7A. Quantitative and Qualitative Disclosures about Market Risk 43\\nItem 8. Financial Statements and Supplementary Data 45\\nItem 9. Changes in and Disagreements with Accountants on Accounting and Financial Disclosure 96\\nItem 9A. Controls and Procedures 96\\nItem 9B. Other Information 96\\nItem 9C. Disclosure Regarding Foreign Jurisdictions that Prevent Inspections 96\\n\\nPART III.\\n\\nItem 10. Directors, Executive Officers and Corporate Governance 97\\nItem 11. Executive Compensation 97\\nItem 12. Security Ownership of Certain Beneficial Owners and Management and Related Stockholder Matters 97\\nItem 13. Certain Relationships and Related Transactions, and Director Independence 97\\nItem 14. Principal Accountant Fees and Services 97\\n\\nPART IV.\\n\\nItem 15. Exhibits and Financial Statement Schedules 98\\nItem 16. Summary 115\\nSignatures 116\\n\\n--- Page 2 End ---\\n\\n\\n\\n--- Page 3 Start ---\\n\\n# Note 4 \\u2013 Goodwill and Intangible Assets\\n\\nGoodwill decreased $7 million within the automotive segment from $207 million as of December 31, 2020 to $200 million as of\\nDecember 31, 2021. There were no accumulated impairment losses as of December 31, 2021 and 2020.\\n\\nInformation regarding our intangible assets including assets recognized from our acquisitions was as follows (in millions):\\n\\n| | December 31, 2021 | | | | December 31, 2020 | | |\\n| :---------------------------------- | :--------------- | :------------------- | :-- | :--- | :--------------- | :------------------- | :-- | :--- |\\n|  | Gross Carrying Amount | Accumulated Amortization | Other | Net Carrying Amount | Gross Carrying Amount | Accumulated Amortization | Other | Net Carrying Amount |\\n| Finite-lived intangible assets: | | | | | | | | |\\n| Developed technology | $ 299 | $ (150) | $ 3 | $ 152 | $ 302 | $ (111) | $ 3 | $ 194 |\\n| Trade names | 2 | (1) | \\u2013 | 1 | 3 | (1) | \\u2013 | 2 |\\n| Favorable contracts and leases, net | 113 | (40) | \\u2013 | 73 | 113 | (32) | \\u2013 | 81 |\\n| Other | 36 | (21) | 1 | 16 | 38 | (18) | 1 | 21 |\\n| Total finite-lived intangible assets | 450 | (212) | 4 | 242 | 456 | (162) | 4 | 298 |\\n| Indefinite-lived intangible assets: | | | | | | | | |\\n| Gigafactory Nevada water rights | 15 | \\u2013 | \\u2013 | 15 | 15 | \\u2013 | \\u2013 | 15 |\\n| Total intangible assets | $ 465 | $ (212) | $ 4 | $ 257 | $ 471 | $ (162) | $ 4 | $ 313 |\\n\\nAmortization expense during the years ended December 31, 2021, 2020 and 2019 was $51 million, $51 million and $44 million,\\nrespectively.\\n\\nTotal future amortization expense for finite-lived intangible assets was estimated as follows (in millions):\\n\\n|  |  |\\n| :---------------- | :- |\\n| 2022 | $ 49 |\\n| 2023 | 43 |\\n| 2024 | 28 |\\n| 2025 | 28 |\\n| 2026 | 28 |\\n| Thereafter | 66 |\\n| Total | $ 242 |\\n\\n\",\n",
      "                \"document_id\": \"a468ce48-18ab-4eee-a0ea-2040c3569b65\",\n",
      "                \"section_id\": \"5c04ca12-99c1-4461-9523-78c90c3ab2bf\",\n",
      "                \"section_heading\": \"FORM 10-K\",\n",
      "                \"chunk_index\": 0,\n",
      "                \"doc_specific_type\": \"Annual Report\",\n",
      "                \"doc_year\": 2021,\n",
      "                \"doc_quarter\": 4,\n",
      "                \"company_name\": \"Tesla, Inc.\",\n",
      "                \"report_date\": \"2021-12-31\",\n",
      "                \"similarity_score\": 0.528680731159552,\n",
      "                \"document_filename\": \"10k_tesla_3_pages.pdf\"\n",
      "              },\n",
      "              {\n",
      "                \"id\": \"61b528a0-80ae-43bf-a3a6-02473f4749f9\",\n",
      "                \"chunk_text\": \"--- Page 1 Start ---\\n\\n```markdown\",\n",
      "                \"document_id\": \"a468ce48-18ab-4eee-a0ea-2040c3569b65\",\n",
      "                \"section_id\": \"c76b283e-ac7b-4488-b095-41e5b78d0631\",\n",
      "                \"section_heading\": \"Document Start\",\n",
      "                \"chunk_index\": 0,\n",
      "                \"doc_specific_type\": \"Annual Report\",\n",
      "                \"doc_year\": 2021,\n",
      "                \"doc_quarter\": 4,\n",
      "                \"company_name\": \"Tesla, Inc.\",\n",
      "                \"report_date\": \"2021-12-31\",\n",
      "                \"similarity_score\": 0.797982585550392,\n",
      "                \"document_filename\": \"10k_tesla_3_pages.pdf\"\n",
      "              },\n",
      "              {\n",
      "                \"id\": \"e0203ee1-3a05-4e62-a11e-a0c0e5f66089\",\n",
      "                \"chunk_text\": \"# UNITED STATES\",\n",
      "                \"document_id\": \"a468ce48-18ab-4eee-a0ea-2040c3569b65\",\n",
      "                \"section_id\": \"584498b5-1ea5-4a48-9e9f-16ec32ee29b6\",\n",
      "                \"section_heading\": \"UNITED STATES\",\n",
      "                \"chunk_index\": 0,\n",
      "                \"doc_specific_type\": \"Annual Report\",\n",
      "                \"doc_year\": 2021,\n",
      "                \"doc_quarter\": 4,\n",
      "                \"company_name\": \"Tesla, Inc.\",\n",
      "                \"report_date\": \"2021-12-31\",\n",
      "                \"similarity_score\": 0.801000603914187,\n",
      "                \"document_filename\": \"10k_tesla_3_pages.pdf\"\n",
      "              },\n",
      "              {\n",
      "                \"id\": \"7b5b62f5-a011-4eb7-9bb9-281560ee34e3\",\n",
      "                \"chunk_text\": \"# SECURITIES AND EXCHANGE COMMISSION\",\n",
      "                \"document_id\": \"a468ce48-18ab-4eee-a0ea-2040c3569b65\",\n",
      "                \"section_id\": \"dda5d208-b4b7-444a-8b01-5cb783bf2678\",\n",
      "                \"section_heading\": \"SECURITIES AND EXCHANGE COMMISSION\",\n",
      "                \"chunk_index\": 0,\n",
      "                \"doc_specific_type\": \"Annual Report\",\n",
      "                \"doc_year\": 2021,\n",
      "                \"doc_quarter\": 4,\n",
      "                \"company_name\": \"Tesla, Inc.\",\n",
      "                \"report_date\": \"2021-12-31\",\n",
      "                \"similarity_score\": 0.811644189161754,\n",
      "                \"document_filename\": \"10k_tesla_3_pages.pdf\"\n",
      "              }\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"parts\": [\n",
      "      {\n",
      "        \"text\": \"\\nBased on the user's original question: \\\"Whats the Gross Carrying Amount for Total intangible assets for tesla in 2021? Create a report of tesla for 2021 in markdown i can copy.\\\"\\nAnd the following information snippets I retrieved for you:\\n\\nOkay, I have retrieved the following information snippets for you:\\n\\n[Snippet 1]\\nSource Document: 10k_tesla_3_pages.pdf\\nSource Section ID: 5c04ca12-99c1-4461-9523-78c90c3ab2bf\\nSource Section Heading: FORM 10-K\\nContent:\\n## FORM 10-K\\n\\n(Mark One)\\n\\u2611 ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE\\nACT OF 1934\\n\\nFor the fiscal year ended December 31, 2021\\nOR\\n\\nTRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES\\nEXCHANGE ACT OF 1934\\n\\nFor the transition period from ______ to ______\\nCommission File Number: 001-34756\\n\\nTesla, Inc.\\n(Exact name of registrant as specified in its charter)\\n\\nDelaware\\n(State or other jurisdiction of\\nincorporation or organization)\\n\\n91-2197729\\n(I.R.S. Employer\\nIdentification No.)\\n\\n13101 Tesla Road\\nAustin, Texas\\n(Address of principal executive offices)\\n\\n78725\\n(Zip Code)\\n\\n(512) 516-8177\\n(Registrant's telephone number, including area code)\\n\\nSecurities registered pursuant to Section 12(b) of the Act:\\n\\n| Title of each class | Trading Symbol(s) | Name of each exchange on which registered |\\n|---|---|---|\\n| Common stock | TSLA | The Nasdaq Global Select Market |\\n\\nSecurities registered pursuant to Section 12(g) of the Act:\\nNone\\n\\nIndicate by check mark whether the registrant is a well-known seasoned issuer, as defined in Rule 405 of the Securities Act. Yes\\n\\u25a1 No \\u2611\\n\\nIndicate by check mark if the registrant is not required to file reports pursuant to Section 13 or 15(d) of the Act. Yes \\u25a1 No \\u2611\\n\\nIndicate by check mark whether the registrant (1) has filed all reports required to be filed by Section 13 or 15(d) of the Securities\\nExchange Act of 1934 (\\u201cExchange Act\\\") during the preceding 12 months (or for such shorter period that the registrant was required to\\nfile such reports), and (2) has been subject to such filing requirements for the past 90 days. Yes \\u2611 No \\u25a1\\n\\nIndicate by check mark whether the registrant has submitted electronically every Interactive Data File required to be submitted\\npursuant to Rule 405 of Regulation S-T (\\u00a7232.405 of this chapter) during the preceding 12 months (or for such shorter period that the\\nregistrant was required to submit such files). Yes \\u2611 No \\u25a1\\n\\nIndicate by check mark whether the registrant is a large accelerated filer, an accelerated filer, a non-accelerated filer, a smaller\\nreporting company, or an emerging growth company. See the definitions of \\u201clarge accelerated filer,\\\" \\u201caccelerated filer,\\u201d \\u201csmaller\\nreporting company\\\" and \\\"emerging growth company\\\" in Rule 12b-2 of the Exchange Act:\\n\\n\\u2611 Large accelerated filer\\n\\u25a1 Non-accelerated filer\\n\\u25a1 Emerging growth company\\n\\n\\u25a1 Accelerated filer\\n\\u25a1 Smaller reporting company\\n\\nIf an emerging growth company, indicate by check mark if the registrant has elected not to use the extended transition period for\\ncomplying with any new or revised financial accounting standards provided pursuant to Section 13(a) of the Exchange Act. \\u25a1\\n```\\n\\n--- Page 1 End ---\\n\\n\\n\\n--- Page 2 Start ---\\n\\nTESLA, INC.\\n\\nANNUAL REPORT ON FORM 10-K FOR THE YEAR ENDED DECEMBER 31, 2021\\n\\nINDEX\\n\\nPage\\n\\nPART I.\\n\\nItem 1. Business 4\\nItem 1A. Risk Factors 14\\nItem 1B. Unresolved Staff Comments 28\\nItem 2. Properties 28\\nItem 3. Legal Proceedings 28\\nItem 4. Mine Safety Disclosures 28\\n\\nPART II.\\n\\nItem 5. Market for Registrant's Common Equity, Related Stockholder Matters and Issuer Purchases of Equity\\nSecurities 29\\nItem 6. [Reserved] 30\\nItem 7. Management's Discussion and Analysis of Financial Condition and Results of Operations 31\\nItem 7A. Quantitative and Qualitative Disclosures about Market Risk 43\\nItem 8. Financial Statements and Supplementary Data 45\\nItem 9. Changes in and Disagreements with Accountants on Accounting and Financial Disclosure 96\\nItem 9A. Controls and Procedures 96\\nItem 9B. Other Information 96\\nItem 9C. Disclosure Regarding Foreign Jurisdictions that Prevent Inspections 96\\n\\nPART III.\\n\\nItem 10. Directors, Executive Officers and Corporate Governance 97\\nItem 11. Executive Compensation 97\\nItem 12. Security Ownership of Certain Beneficial Owners and Management and Related Stockholder Matters 97\\nItem 13. Certain Relationships and Related Transactions, and Director Independence 97\\nItem 14. Principal Accountant Fees and Services 97\\n\\nPART IV.\\n\\nItem 15. Exhibits and Financial Statement Schedules 98\\nItem 16. Summary 115\\nSignatures 116\\n\\n--- Page 2 End ---\\n\\n\\n\\n--- Page 3 Start ---\\n\\n# Note 4 \\u2013 Goodwill and Intangible Assets\\n\\nGoodwill decreased $7 million within the automotive segment from $207 million as of December 31, 2020 to $200 million as of\\nDecember 31, 2021. There were no accumulated impairment losses as of December 31, 2021 and 2020.\\n\\nInformation regarding our intangible assets including assets recognized from our acquisitions was as follows (in millions):\\n\\n| | December 31, 2021 | | | | December 31, 2020 | | |\\n| :---------------------------------- | :--------------- | :------------------- | :-- | :--- | :--------------- | :------------------- | :-- | :--- |\\n|  | Gross Carrying Amount | Accumulated Amortization | Other | Net Carrying Amount | Gross Carrying Amount | Accumulated Amortization | Other | Net Carrying Amount |\\n| Finite-lived intangible assets: | | | | | | | | |\\n| Developed technology | $ 299 | $ (150) | $ 3 | $ 152 | $ 302 | $ (111) | $ 3 | $ 194 |\\n| Trade names | 2 | (1) | \\u2013 | 1 | 3 | (1) | \\u2013 | 2 |\\n| Favorable contracts and leases, net | 113 | (40) | \\u2013 | 73 | 113 | (32) | \\u2013 | 81 |\\n| Other | 36 | (21) | 1 | 16 | 38 | (18) | 1 | 21 |\\n| Total finite-lived intangible assets | 450 | (212) | 4 | 242 | 456 | (162) | 4 | 298 |\\n| Indefinite-lived intangible assets: | | | | | | | | |\\n| Gigafactory Nevada water rights | 15 | \\u2013 | \\u2013 | 15 | 15 | \\u2013 | \\u2013 | 15 |\\n| Total intangible assets | $ 465 | $ (212) | $ 4 | $ 257 | $ 471 | $ (162) | $ 4 | $ 313 |\\n\\nAmortization expense during the years ended December 31, 2021, 2020 and 2019 was $51 million, $51 million and $44 million,\\nrespectively.\\n\\nTotal future amortization expense for finite-lived intangible assets was estimated as follows (in millions):\\n\\n|  |  |\\n| :---------------- | :- |\\n| 2022 | $ 49 |\\n| 2023 | 43 |\\n| 2024 | 28 |\\n| 2025 | 28 |\\n| 2026 | 28 |\\n| Thereafter | 66 |\\n| Total | $ 242 |\\n\\n\\n\\n[Snippet 2]\\nSource Document: 10k_tesla_3_pages.pdf\\nSource Section ID: c76b283e-ac7b-4488-b095-41e5b78d0631\\nSource Section Heading: Document Start\\nContent:\\n--- Page 1 Start ---\\n\\n```markdown\\n\\n[Snippet 3]\\nSource Document: 10k_tesla_3_pages.pdf\\nSource Section ID: 584498b5-1ea5-4a48-9e9f-16ec32ee29b6\\nSource Section Heading: UNITED STATES\\nContent:\\n# UNITED STATES\\n\\n[Snippet 4]\\nSource Document: 10k_tesla_3_pages.pdf\\nSource Section ID: dda5d208-b4b7-444a-8b01-5cb783bf2678\\nSource Section Heading: SECURITIES AND EXCHANGE COMMISSION\\nContent:\\n# SECURITIES AND EXCHANGE COMMISSION\\n\\n\\n\\nPlease perform the following steps:\\n1. Carefully review the information snippets.\\n2. Answer the user's original question using ONLY the information present in these snippets. Do not use any prior knowledge or external information.\\n3. If the answer cannot be found in the provided snippets, clearly state that the information is not available in the documents. Your response should still be polite and acknowledge the query.\\n4. After your answer, include a \\\"Sources:\\\" section on a new line.\\n5. In the \\\"Sources:\\\" section, list each snippet number you explicitly used to construct your answer, along with its corresponding document name and section ID, formatted as a Markdown link.\\n6. The Markdown link format MUST be exactly: `[<Snippet Number>. (<Source Document Name>)](https://www.stackifier.com/document?section_id=<Source Section ID>)`\\n   - Replace `<Snippet Number>` with the number from the \\\"[Snippet X]\\\" heading in the snippets I provided (e.g., 1, 2).\\n   - Replace `<Source Document Name>` with the 'Source Document' name provided for that snippet.\\n   - Replace `<Source Section ID>` with the 'Source Section ID' provided for that snippet.\\n\\nExample of a \\\"Sources:\\\" section entry if Snippet 1 was from 'report.pdf' with section ID 'abc-123':\\nSources:\\n[1. (report.pdf)](https://www.stackifier.com/document?section_id=abc-123)\\n\\nIf you use information from multiple snippets, list them all under the \\\"Sources:\\\" heading, each on a new line using the specified Markdown link format.\\nIf no snippets were found or if the snippets do not contain the answer, do not include a \\\"Sources:\\\" section, but state clearly that the information could not be found in the provided documents based on the provided documents.\\n\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "]\n",
      "\n",
      "--- Received response from second Gemini call (Final Answer) ---\n",
      "\n",
      "\n",
      "****************************************\n",
      "--- Final Answer Text from Gemini ---\n",
      "****************************************\n",
      "**Tesla, Inc. Intangible Assets Report for 2021**\n",
      "\n",
      "Based on Tesla's Annual Report on Form 10-K for the fiscal year ended December 31, 2021, the Gross Carrying Amount for Total intangible assets as of December 31, 2021 was $465 million.\n",
      "\n",
      "Sources:\n",
      "[1. (10k_tesla_3_pages.pdf)](https://www.stackifier.com/document?section_id=5c04ca12-99c1-4461-9523-78c90c3ab2bf)\n",
      "****************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add project root to sys.path\n",
    "import sys\n",
    "import os\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "import os\n",
    "import uuid\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from supabase import create_client, Client\n",
    "# Assuming this is the correct alias for google.generativeai.types\n",
    "# Also ensure types.GenerateContentConfig is available via this import\n",
    "from google.genai import types\n",
    "import traceback # Import traceback for better error logging\n",
    "\n",
    "# Ensure you are using the correct import for Gemini's client library\n",
    "# If google.genai.types is not found, it's likely google.generativeai.types\n",
    "# try:\n",
    "#     from google.genai import types\n",
    "# except ImportError:\n",
    "#     from google.generativeai import types\n",
    "\n",
    "\n",
    "# Assuming these imports are correct based on your project structure\n",
    "from src.llm.OpenAIClient import OpenAIClient\n",
    "from src.llm.GeminiClient import GeminiClient\n",
    "from src.storage.SupabaseService import SupabaseService\n",
    "from src.enums import FinancialDocSpecificType\n",
    "\n",
    "# --- HELPER FUNCTION: Serialize conversation history for printing ---\n",
    "# This fixes the AttributeError when trying to print Content objects directly\n",
    "def serialize_conversation_history(history: list) -> list:\n",
    "    \"\"\"\n",
    "    Manually serializes conversation history (list of Content objects)\n",
    "    into a list of dictionaries for printing.\n",
    "    Handles basic text, function_call, and function_response parts.\n",
    "    \"\"\"\n",
    "    serializable_history = []\n",
    "    for content_item in history:\n",
    "        # Check if content_item is already a dict (e.g., from a previous manual step)\n",
    "        if isinstance(content_item, dict):\n",
    "            serializable_history.append(content_item)\n",
    "            continue\n",
    "\n",
    "        # Assume it's a types.Content object or similar structure\n",
    "        item_dict = {\"role\": content_item.role, \"parts\": []}\n",
    "        # Ensure parts exist and are not None before iterating\n",
    "        if hasattr(content_item, 'parts') and content_item.parts is not None:\n",
    "            for part_item in content_item.parts:\n",
    "                part_dict = {}\n",
    "                # Check for text part\n",
    "                if hasattr(part_item, 'text') and part_item.text is not None:\n",
    "                    part_dict['text'] = part_item.text\n",
    "                # Check for function_call part\n",
    "                if hasattr(part_item, 'function_call') and part_item.function_call:\n",
    "                    part_dict['function_call'] = {\n",
    "                        \"name\": part_item.function_call.name,\n",
    "                        # Convert Pydantic object to dict, handle empty args\n",
    "                        \"args\": dict(part_item.function_call.args) if hasattr(part_item.function_call.args, 'items') else {}\n",
    "                    }\n",
    "                # Check for function_response part\n",
    "                if hasattr(part_item, 'function_response') and part_item.function_response:\n",
    "                    # The 'response' field in FunctionResponsePart itself contains the data\n",
    "                    response_data = part_item.function_response.response\n",
    "                    # Assuming response_data is the dict loaded from JSON from your tool\n",
    "                    part_dict['function_response'] = {\n",
    "                        \"name\": part_item.function_response.name,\n",
    "                        \"response\": response_data\n",
    "                    }\n",
    "                # Check for other part types if needed (e.g., inline_data, file_data)\n",
    "                # Example for inline_data (like images):\n",
    "                # if hasattr(part_item, 'inline_data') and part_item.inline_data:\n",
    "                #     part_dict['inline_data'] = {\n",
    "                #         \"mime_type\": part_item.inline_data.mime_type,\n",
    "                #         \"data\": f\"...data_bytes_or_base64...\" # Represent appropriately\n",
    "                #     }\n",
    "\n",
    "                if part_dict: # Only add if part_dict is not empty\n",
    "                    item_dict[\"parts\"].append(part_dict)\n",
    "        serializable_history.append(item_dict)\n",
    "    return serializable_history\n",
    "\n",
    "\n",
    "# --- HELPER FUNCTION: Format retrieved chunks for the LLM ---\n",
    "# This structures the retrieved data clearly for the LLM to use for answering and citing\n",
    "def format_chunks_for_llm(retrieved_chunks_json: str) -> str:\n",
    "    \"\"\"\n",
    "    Formats the JSON string of retrieved chunks into a readable text block\n",
    "    for the LLM, including necessary details for citation.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        chunks = json.loads(retrieved_chunks_json)\n",
    "        # Handle empty or error responses from retrieve_financial_chunks\n",
    "        if not chunks:\n",
    "            return \"No specific information snippets were found to answer the question.\\n\"\n",
    "        if isinstance(chunks, dict) and \"error\" in chunks:\n",
    "             return f\"Could not retrieve information snippets: {chunks['error']}\\n\"\n",
    "\n",
    "\n",
    "        formatted_text = \"Okay, I have retrieved the following information snippets for you:\\n\\n\"\n",
    "        for i, chunk_data in enumerate(chunks):\n",
    "            snippet_num = i + 1\n",
    "            # Ensure these keys match what your `retrieve_financial_chunks` actually returns from the RPC\n",
    "            # Added more robust checks and fallbacks here\n",
    "            doc_name = chunk_data.get(\"document_filename\")\n",
    "            if doc_name is None:\n",
    "                 doc_name = chunk_data.get(\"filename\", \"Unknown Document\") # Fallback to 'filename' key if RPC uses that\n",
    "                 print(f\"  Warning: 'document_filename' missing from chunk_data, used fallback 'filename': {doc_name}\")\n",
    "\n",
    "            sec_id = chunk_data.get(\"section_id\")\n",
    "            if sec_id is None:\n",
    "                 sec_id = chunk_data.get(\"id\", \"unknown_section_missing_from_rpc\") # Fallback to chunk 'id'\n",
    "                 print(f\"  Warning: 'section_id' missing from chunk_data, used fallback 'id': {sec_id}\")\n",
    "\n",
    "            sec_heading = chunk_data.get(\"section_heading\", \"N/A\") # Make sure this is returned by RPC\n",
    "            chunk_text_content = chunk_data.get(\"chunk_text\", \"No content.\")\n",
    "\n",
    "            formatted_text += f\"[Snippet {snippet_num}]\\n\"\n",
    "            formatted_text += f\"Source Document: {doc_name}\\n\"\n",
    "            formatted_text += f\"Source Section ID: {sec_id}\\n\"\n",
    "            formatted_text += f\"Source Section Heading: {sec_heading}\\n\" # Good for LLM context\n",
    "            formatted_text += f\"Content:\\n{chunk_text_content}\\n\\n\"\n",
    "\n",
    "        return formatted_text\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error decoding JSON in format_chunks_for_llm: {traceback.format_exc()}\")\n",
    "        return \"Error: Could not parse the retrieved information snippets for formatting.\\n\"\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred in format_chunks_for_llm: {e}\\n{traceback.format_exc()}\")\n",
    "        return f\"An unexpected error occurred while formatting snippets: {str(e)}\\n\"\n",
    "\n",
    "# --- PROMPT FUNCTION: Craft instructions for final answer + citation links ---\n",
    "YOUR_APP_DOMAIN = \"www.stackifier.com\" # As per your example, make this configurable if needed\n",
    "\n",
    "def create_final_answer_instructions(user_original_query: str, formatted_snippets_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Creates the detailed instructions for the LLM to generate the final answer,\n",
    "    incorporating the formatted snippets and specifying the Markdown citation format.\n",
    "    \"\"\"\n",
    "    instructions = f\"\"\"\n",
    "Based on the user's original question: \"{user_original_query}\"\n",
    "And the following information snippets I retrieved for you:\n",
    "\n",
    "{formatted_snippets_text}\n",
    "\n",
    "Please perform the following steps:\n",
    "1. Carefully review the information snippets.\n",
    "2. Answer the user's original question using ONLY the information present in these snippets. Do not use any prior knowledge or external information.\n",
    "3. If the answer cannot be found in the provided snippets, clearly state that the information is not available in the documents. Your response should still be polite and acknowledge the query.\n",
    "4. After your answer, include a \"Sources:\" section on a new line.\n",
    "5. In the \"Sources:\" section, list each snippet number you explicitly used to construct your answer, along with its corresponding document name and section ID, formatted as a Markdown link.\n",
    "6. The Markdown link format MUST be exactly: `[<Snippet Number>. (<Source Document Name>)](https://{YOUR_APP_DOMAIN}/document?section_id=<Source Section ID>)`\n",
    "   - Replace `<Snippet Number>` with the number from the \"[Snippet X]\" heading in the snippets I provided (e.g., 1, 2).\n",
    "   - Replace `<Source Document Name>` with the 'Source Document' name provided for that snippet.\n",
    "   - Replace `<Source Section ID>` with the 'Source Section ID' provided for that snippet.\n",
    "\n",
    "Example of a \"Sources:\" section entry if Snippet 1 was from 'report.pdf' with section ID 'abc-123':\n",
    "Sources:\n",
    "[1. (report.pdf)](https://{YOUR_APP_DOMAIN}/document?section_id=abc-123)\n",
    "\n",
    "If you use information from multiple snippets, list them all under the \"Sources:\" heading, each on a new line using the specified Markdown link format.\n",
    "If no snippets were found or if the snippets do not contain the answer, do not include a \"Sources:\" section, but state clearly that the information could not be found in the provided documents based on the provided documents.\n",
    "\"\"\"\n",
    "    return instructions\n",
    "\n",
    "\n",
    "def retrieve_financial_chunks(\n",
    "    query_text: str,\n",
    "    user_id: str,\n",
    "    match_count: int = 5,\n",
    "    doc_specific_type: str = None,\n",
    "    company_name: str = None,\n",
    "    doc_year_start: int = None,\n",
    "    doc_year_end: int = None,\n",
    "    doc_quarter: int = None\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Retrieves relevant financial document chunks from Supabase based on a query\n",
    "    and optional metadata filters for a specific user.\n",
    "\n",
    "    Returns:\n",
    "        A JSON string representation of the list of retrieved chunk dictionaries,\n",
    "        or a JSON string with an error message.\n",
    "    IMPORTANT: Ensure the RPC 'match_chunks' returns 'document_filename' (from documents table)\n",
    "               and 'section_id' (the section UUID from sections table) for each chunk,\n",
    "               in addition to 'chunk_text', 'section_heading', etc.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Executing Tool: retrieve_financial_chunks ---\")\n",
    "    print(f\"  Query: '{query_text}'\")\n",
    "    print(f\"  User ID: {user_id}\")\n",
    "    print(f\"  Filters: Type={doc_specific_type}, Company={company_name}, Year={doc_year_start}-{doc_year_end}, Qtr={doc_quarter}\")\n",
    "\n",
    "    global openai_client, supabase_service # Ensure these are properly initialized in the global scope\n",
    "    if openai_client is None or supabase_service is None:\n",
    "         return json.dumps({\"error\": \"Clients not initialized. OpenAI or Supabase service is None.\"})\n",
    "\n",
    "    try:\n",
    "        # --- Step 1: Generate Embedding for the query ---\n",
    "        query_embedding_list = openai_client.get_embeddings([query_text])\n",
    "        if not query_embedding_list:\n",
    "            print(f\"  Error: Failed to generate query embedding.\")\n",
    "            return json.dumps({\"error\": \"Failed to generate query embedding.\"})\n",
    "        query_embedding = query_embedding_list[0]\n",
    "        print(f\"  Query embedding generated.\")\n",
    "\n",
    "        # --- Step 2: Call Supabase RPC to find matching chunks ---\n",
    "        print(f\"  Calling Supabase RPC 'match_chunks'...\")\n",
    "        # Ensure your 'match_chunks' RPC in Supabase handles the filters and returns the required fields.\n",
    "        response = supabase_service.client.rpc(\n",
    "            'match_chunks', # This RPC must exist and return document_filename and section_id\n",
    "            {\n",
    "                'query_embedding': query_embedding,\n",
    "                'match_count': match_count,\n",
    "                'user_id': user_id,\n",
    "                'p_doc_specific_type': doc_specific_type,\n",
    "                'p_company_name': company_name,\n",
    "                'p_doc_year_start': doc_year_start,\n",
    "                'p_doc_year_end': doc_year_end,\n",
    "                'p_doc_quarter': doc_quarter\n",
    "            }\n",
    "        ).execute()\n",
    "\n",
    "        # --- Step 3: Process RPC response ---\n",
    "        if response.data is not None: # Check if data is not None (even empty list is valid data)\n",
    "            print(f\"  Retrieved {len(response.data)} chunks from Supabase.\")\n",
    "            processed_data = []\n",
    "            for chunk_dict in response.data: # chunk_dict is a dictionary from the RPC\n",
    "                 processed_chunk = {}\n",
    "                 for key, value in chunk_dict.items():\n",
    "                     # Convert UUIDs to strings for JSON serialization if needed\n",
    "                     if isinstance(value, uuid.UUID):\n",
    "                         processed_chunk[key] = str(value)\n",
    "                     else:\n",
    "                         processed_chunk[key] = value\n",
    "\n",
    "                 # --- Critical Check: Ensure required keys for citation are present ---\n",
    "                 # The RPC *must* return 'document_filename' and 'section_id'.\n",
    "                 # Add placeholders/warnings if they are missing, but the RPC should be fixed.\n",
    "                 if 'document_filename' not in processed_chunk or processed_chunk['document_filename'] is None:\n",
    "                     print(f\"  Warning: RPC 'match_chunks' did not return 'document_filename' for a chunk.\")\n",
    "                     processed_chunk['document_filename'] = 'RPC_Missing_Doc_Name'\n",
    "                 if 'section_id' not in processed_chunk or processed_chunk['section_id'] is None:\n",
    "                     print(f\"  Warning: RPC 'match_chunks' did not return 'section_id' for a chunk.\")\n",
    "                     # Fallback to chunk id string if section id is missing, though not ideal for section link\n",
    "                     processed_chunk['section_id'] = str(processed_chunk.get('id', 'RPC_Missing_Section_ID'))\n",
    "                 # Also ensure chunk_text and section_heading are present for formatting\n",
    "                 if 'chunk_text' not in processed_chunk:\n",
    "                      processed_chunk['chunk_text'] = 'Chunk text missing from RPC.'\n",
    "                 if 'section_heading' not in processed_chunk:\n",
    "                      processed_chunk['section_heading'] = 'Section heading missing from RPC.'\n",
    "\n",
    "\n",
    "                 processed_data.append(processed_chunk)\n",
    "\n",
    "            result_json_string = json.dumps(processed_data, indent=2)\n",
    "            # Avoid printing potentially massive JSON result entirely\n",
    "            print(f\"  Returning JSON result ({len(result_json_string)} chars, first 500 for brevity):\\n{result_json_string[:500]}...\")\n",
    "            return result_json_string\n",
    "        elif hasattr(response, 'error') and response.error:\n",
    "             error_msg = f\"Supabase RPC 'match_chunks' error: {response.error.message if hasattr(response.error, 'message') else response.error}\"\n",
    "             print(f\"  Error: {error_msg}\")\n",
    "             return json.dumps({\"error\": error_msg})\n",
    "        else:\n",
    "            # This case handles unexpected response structures where data and error are missing\n",
    "            print(\"  Received unexpected response structure from Supabase RPC 'match_chunks'.\")\n",
    "            print(f\"  Response object type: {type(response)}\")\n",
    "            # Attempt to get any response content if available\n",
    "            try:\n",
    "                print(f\"  Response data: {response.data}\")\n",
    "                print(f\"  Response error: {response.error}\")\n",
    "            except Exception as print_exc:\n",
    "                print(f\"  Could not print response details: {print_exc}\")\n",
    "            return json.dumps({\"error\": \"Unexpected response from Supabase RPC. Data and error fields were not accessible or were None when expected.\"})\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        # Catch any other exceptions during embedding or RPC call setup/execution\n",
    "        print(f\"An unexpected error occurred during chunk retrieval: {str(e)}\\n{traceback.format_exc()}\")\n",
    "        return json.dumps({\"error\": f\"An unexpected error occurred during chunk retrieval: {str(e)}\"})\n",
    "\n",
    "\n",
    "# --- Define Function Declaration for Gemini ---\n",
    "# This tells the LLM about the tool it can use\n",
    "retrieve_chunks_declaration = {\n",
    "    \"name\": \"retrieve_financial_chunks\",\n",
    "    \"description\": \"Searches and retrieves relevant text chunks from the user's uploaded financial documents based on their query and optional filters like company name, document type, year range, or quarter. Always use this tool to find information before answering questions about the user's financial documents.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query_text\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The user's original question or a refined search query based on their question.\",\n",
    "            },\n",
    "            \"match_count\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"The maximum number of relevant text chunks to return. Default is 5. Use a reasonable number like 5-10.\",\n",
    "            },\n",
    "            \"doc_specific_type\": {\n",
    "                \"type\": \"string\",\n",
    "                # Ensure FinancialDocSpecificType is correctly imported and has a .value attribute\n",
    "                \"description\": f\"Filter results to a specific document type. Examples: {', '.join([item.value for item in FinancialDocSpecificType if item != FinancialDocSpecificType.UNKNOWN and item.value is not None])}. Leave empty if no specific type is mentioned.\",\n",
    "            },\n",
    "            \"company_name\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Filter results to a specific company name mentioned in the query. Use the most likely name if variations exist (e.g., 'Tesla' for 'Tesla, Inc.'). Leave empty if no company is mentioned.\",\n",
    "            },\n",
    "            \"doc_year_start\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"The starting fiscal year for filtering (e.g., 2021). Extract from the user's query if a year or date range is specified. Leave empty if no start year is specified.\",\n",
    "            },\n",
    "            \"doc_year_end\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"The ending fiscal year for filtering (e.g., 2021). Use the same year as start year if only one year is mentioned. Leave empty if no end year is specified.\",\n",
    "            },\n",
    "            \"doc_quarter\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"Filter results to a specific fiscal quarter (1, 2, 3, or 4). Extract if mentioned in the query. Use -1 or leave empty if no quarter is mentioned.\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"query_text\"] # query_text is mandatory for the tool\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "# --- Configuration and Globals ---\n",
    "load_dotenv()\n",
    "TEST_EMAIL = os.environ.get(\"TEST_EMAIL\")\n",
    "TEST_PASSWORD = os.environ.get(\"TEST_PASSWORD\")\n",
    "if not TEST_EMAIL or not TEST_PASSWORD:\n",
    "    raise ValueError(\"TEST_EMAIL and TEST_PASSWORD must be set in your .env file.\")\n",
    "\n",
    "# Keep track of conversation history. This is crucial for multi-turn interactions.\n",
    "# Gemini API expects history in a specific turn-based format (user, model, user, model, ...)\n",
    "conversation_history = []\n",
    "\n",
    "# --- User Query ---\n",
    "user_query = \"Whats the Gross Carrying Amount for Total intangible assets for tesla in 2021? Create a report of tesla for 2021 in markdown i can copy.\"\n",
    "print(f\"\\n--- User Query ---\")\n",
    "print(user_query)\n",
    "\n",
    "# --- Initialize Clients and Authenticate with Supabase ---\n",
    "openai_client = None\n",
    "gemini_client = None\n",
    "supabase_service = None\n",
    "authenticated_user_id_str = None\n",
    "auth_client = None\n",
    "\n",
    "try:\n",
    "    print(\"\\n--- Initializing clients and authenticating ---\")\n",
    "    # Initialize OpenAI client for embeddings\n",
    "    openai_client = OpenAIClient()\n",
    "    # Initialize Gemini client for LLM interactions\n",
    "    # GeminiClient assumes GEMINI_API_KEY is in .env\n",
    "    gemini_client = GeminiClient()\n",
    "\n",
    "    # Initialize Supabase client and authenticate test user\n",
    "    supabase_url = os.environ.get(\"SUPABASE_URL\")\n",
    "    # Use ANON_KEY for RLS-enabled access\n",
    "    supabase_key = os.environ.get(\"SUPABASE_ANON_KEY\")\n",
    "    if not supabase_url or not supabase_key:\n",
    "        raise ValueError(\"SUPABASE_URL and SUPABASE_ANON_KEY must be set in your .env file.\")\n",
    "\n",
    "    auth_client: Client = create_client(supabase_url, supabase_key)\n",
    "    print(\"Supabase client created.\")\n",
    "\n",
    "    # Authenticate the test user\n",
    "    print(f\"Attempting to sign in with email: {TEST_EMAIL}\")\n",
    "    auth_response = auth_client.auth.sign_in_with_password(\n",
    "        {\"email\": TEST_EMAIL, \"password\": TEST_PASSWORD}\n",
    "    )\n",
    "\n",
    "    # Check if authentication was successful and user object is available\n",
    "    if not auth_response or not auth_response.user:\n",
    "        error_detail = auth_response.error.message if hasattr(auth_response, 'error') and auth_response.error else \"Unknown authentication error\"\n",
    "        raise ConnectionError(f\"Supabase authentication failed: {error_detail}. Check credentials and Supabase Auth settings.\")\n",
    "\n",
    "    # Extract the authenticated user ID (UUID)\n",
    "    authenticated_user_id_str = str(auth_response.user.id)\n",
    "    print(f\"Authentication successful. User ID: {authenticated_user_id_str}\")\n",
    "\n",
    "    # Initialize SupabaseService with the authenticated client\n",
    "    supabase_service = SupabaseService(supabase_client=auth_client)\n",
    "    print(\"Clients initialized and authenticated.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Initialization or Authentication Error: {str(e)}\\n{traceback.format_exc()}\")\n",
    "    sys.exit(1) # Exit if initialization fails\n",
    "\n",
    "# --- Define the Tool for Gemini ---\n",
    "# This tells the LLM about the function it has access to\n",
    "retrieval_tool = types.Tool(function_declarations=[retrieve_chunks_declaration])\n",
    "# Using the model from your log, or a recommended latest flash version\n",
    "# gemini_model_name = \"gemini-2.5-flash-preview-04-17\" # If you must use this specific preview\n",
    "gemini_model_name = \"gemini-2.5-flash-preview-04-17\" # Using latest flash model recommended for general use\n",
    "\n",
    "\n",
    "# --- Function Calling Loop ---\n",
    "# This block simulates the interaction between the LLM and your tool\n",
    "try:\n",
    "    # 1. First call to LLM: Send user query and retrieval tool definition\n",
    "    print(f\"\\n--- Sending initial query to Gemini ({gemini_model_name}) ---\")\n",
    "    # Add the user's initial query to the conversation history\n",
    "    conversation_history.append(types.Content(role=\"user\", parts=[types.Part(text=user_query)]))\n",
    "\n",
    "    # Print history for debugging using the serialization helper\n",
    "    print(f\"  Conversation History before first call:\\n{json.dumps(serialize_conversation_history(conversation_history), indent=2)}\")\n",
    "\n",
    "\n",
    "    # Send the conversation history and available tools to Gemini\n",
    "    # FIX: Use 'config' parameter with types.GenerateContentConfig for tools\n",
    "    response = gemini_client.client.models.generate_content( # Correctly using gemini_client.client\n",
    "        model=gemini_model_name,\n",
    "        contents=conversation_history,\n",
    "        config=types.GenerateContentConfig(tools=[retrieval_tool]) # Pass tools via config with GenerateContentConfig\n",
    "    )\n",
    "\n",
    "    print(f\"\\n--- Received response from first Gemini call ---\")\n",
    "    # Print the full response structure for inspection (can be verbose)\n",
    "    # print(response)\n",
    "\n",
    "    # Check if the response contains candidates and parts\n",
    "    if not response.candidates or not response.candidates[0].content or not response.candidates[0].content.parts:\n",
    "        print(\"Error: Unexpected response structure or no candidates/parts from Gemini's first call.\")\n",
    "        print(f\"Full response object: {response}\") # Print the full response object for debugging\n",
    "        # Check if there's a prompt feedback error\n",
    "        if hasattr(response, 'prompt_feedback') and response.prompt_feedback:\n",
    "            print(f\"Prompt Feedback: {response.prompt_feedback}\")\n",
    "        sys.exit(1) # Exit if initial call fails\n",
    "\n",
    "    # Get the first part of the model's response\n",
    "    model_response_content = response.candidates[0].content\n",
    "    message_part = model_response_content.parts[0]\n",
    "\n",
    "    # Add the model's response (which might contain a function call) to history\n",
    "    conversation_history.append(model_response_content)\n",
    "    print(f\"\\n  Model's response content (first call) added to history.\")\n",
    "    # Print model response content for debugging using the serialization helper\n",
    "    # print(f\"  Model response content:\\n{serialize_conversation_history([model_response_content])[0]}\")\n",
    "\n",
    "\n",
    "    # 2. Check if LLM requested a function call\n",
    "    if hasattr(message_part, 'function_call') and message_part.function_call:\n",
    "        function_call = message_part.function_call\n",
    "        print(f\"\\n--- Gemini requested function call: '{function_call.name}' ---\")\n",
    "        # LLM args is a Pydantic model-like object, convert to dict for easier use\n",
    "        tool_args = dict(function_call.args)\n",
    "        print(f\"  Raw Arguments from LLM: {tool_args}\")\n",
    "\n",
    "        # 3. Execute the function if it's the one we defined\n",
    "        if function_call.name == \"retrieve_financial_chunks\":\n",
    "            print(\"  Recognized 'retrieve_financial_chunks' call.\")\n",
    "            print(f\"  Extracted tool_args before adding user_id: {tool_args}\")\n",
    "\n",
    "            # --- IMPORTANT: Add authenticated user_id to tool arguments ---\n",
    "            # The user_id comes from authentication, not from the LLM's interpretation of the query.\n",
    "            # It must be passed to our internal function for RLS enforcement.\n",
    "            tool_args['user_id'] = authenticated_user_id_str\n",
    "            print(f\"  Tool_args *including* user_id for execution: {tool_args}\")\n",
    "\n",
    "            # Call the actual Python function that interacts with Supabase/OpenAI\n",
    "            function_result_json = retrieve_financial_chunks(**tool_args)\n",
    "            print(f\"\\n--- Finished executing retrieve_financial_chunks ---\")\n",
    "            # Print a summary of the function result (the JSON string)\n",
    "            print(f\"  Function result (JSON string, first 500 chars):\\n{function_result_json[:500]}...\")\n",
    "\n",
    "\n",
    "            # 4. Second call to LLM: Send function result back AND provide instructions for final answer + citations\n",
    "            print(\"\\n--- Preparing enriched context and instructions for final Gemini call ---\")\n",
    "\n",
    "            # A. Add the raw function response (as structured data) to the conversation history\n",
    "            # This allows the LLM to \"see\" the specific data returned by the tool.\n",
    "            # The response must be a dictionary matching the expected tool response structure.\n",
    "            try:\n",
    "                function_response_data = json.loads(function_result_json)\n",
    "            except json.JSONDecodeError:\n",
    "                 print(f\"Error decoding function result JSON: {function_result_json[:200]}...\")\n",
    "                 function_response_data = {\"error\": \"Invalid JSON from tool.\"} # Send error back to LLM\n",
    "\n",
    "            function_response_part = types.Part.from_function_response(\n",
    "                name=function_call.name,\n",
    "                response={\"result\": function_response_data} # Wrap the result in a 'result' key as used in docs\n",
    "            )\n",
    "            # Per Gemini docs, the function response should be in a \"user\" role part that follows\n",
    "            # the \"model\" role part containing the function_call.\n",
    "            # Our conversation_history structure now:\n",
    "            # 1. User: Original query\n",
    "            # 2. Model: Function call (`model_response_content`)\n",
    "            # 3. User: Function response (`function_response_part`)\n",
    "            conversation_history.append(\n",
    "                 types.Content(role=\"user\", parts=[function_response_part]) # role=\"user\" for function response\n",
    "            )\n",
    "            print(f\"  Raw function response part added to history.\")\n",
    "            # Print for debugging\n",
    "            # print(f\"  Function response part:\\n{serialize_conversation_history([types.Content(role='user', parts=[function_response_part])])[0]}\")\n",
    "\n",
    "\n",
    "            # B. Format the retrieved chunks into a readable text block for the LLM\n",
    "            # This is the context the LLM will actually read to answer the question.\n",
    "            formatted_snippets_text = format_chunks_for_llm(function_result_json)\n",
    "\n",
    "            # C. Create the new detailed instructions for answer generation and citation formatting\n",
    "            final_instructions_text = create_final_answer_instructions(user_query, formatted_snippets_text)\n",
    "\n",
    "            # D. Add these new instructions as another user message to guide the LLM's final response\n",
    "            # This user turn contains the human-readable snippets and the citation instructions.\n",
    "            conversation_history.append(\n",
    "                types.Content(role=\"user\", parts=[types.Part(text=final_instructions_text)])\n",
    "            )\n",
    "            print(f\"  Formatted snippets and citation instructions added to history.\")\n",
    "            # Print instructions for debugging\n",
    "            # print(f\"  Final instructions text (first 500 chars for brevity):\\n{final_instructions_text[:500]}...\")\n",
    "\n",
    "            # Print the conversation history *before* the final call for debugging\n",
    "            print(f\"\\n  Conversation History before second call (final answer generation):\\n{json.dumps(serialize_conversation_history(conversation_history), indent=2)}\")\n",
    "\n",
    "            # --- Step 5: Generate the final response ---\n",
    "            # Send the complete conversation history (including tool call and response, and formatted context)\n",
    "            # FIX: Remove 'config' parameter in the second call as tools are likely not needed here\n",
    "            final_response = gemini_client.client.models.generate_content(\n",
    "                model=gemini_model_name,\n",
    "                contents=conversation_history\n",
    "                # Tools are generally not needed for the final answer generation turn.\n",
    "                # If the LLM needs to call a tool *again* based on the function result,\n",
    "                # you would re-enable the tools here using:\n",
    "                # config=types.GenerateContentConfig(tools=[retrieval_tool])\n",
    "            )\n",
    "\n",
    "            print(f\"\\n--- Received response from second Gemini call (Final Answer) ---\")\n",
    "            # Print the full final response object for inspection\n",
    "            # print(final_response)\n",
    "\n",
    "            # --- Step 6: Extract and print the final answer ---\n",
    "            if final_response.candidates and final_response.candidates[0].content and final_response.candidates[0].content.parts:\n",
    "                 final_model_response_content = final_response.candidates[0].content\n",
    "                 # Add the final model response to history if you plan more turns\n",
    "                 conversation_history.append(final_model_response_content)\n",
    "                 # Print for debugging\n",
    "                 # print(f\"\\n  Final model's response content added to history: {serialize_conversation_history([final_model_response_content])[0]}\")\n",
    "\n",
    "                 # The final answer text should be in the text part\n",
    "                 print(\"\\n\\n****************************************\")\n",
    "                 print(\"--- Final Answer Text from Gemini ---\")\n",
    "                 print(\"****************************************\")\n",
    "                 print(final_response.text) # This should now include Markdown citation links\n",
    "                 print(\"****************************************\\n\")\n",
    "            else:\n",
    "                 print(\"Error: No final response text found after sending function result.\")\n",
    "                 print(f\"Full final response object: {final_response}\")\n",
    "                 if hasattr(final_response, 'prompt_feedback') and final_response.prompt_feedback:\n",
    "                     print(f\"Final Response Prompt Feedback: {final_response.prompt_feedback}\")\n",
    "\n",
    "\n",
    "        else:\n",
    "            # This branch executes if the LLM requested a function call, but it wasn't\n",
    "            # the 'retrieve_financial_chunks' function we defined.\n",
    "            print(f\"Warning: LLM requested unknown function '{function_call.name}'\")\n",
    "            # In a real application, you might send this back to the LLM as a \"tool error\"\n",
    "            # or inform the user. For a simple notebook, we just report and stop.\n",
    "            print(\"Stopping execution due to unknown function call.\")\n",
    "\n",
    "    else:\n",
    "        # This branch executes if the LLM decided to answer the user's query directly\n",
    "        # without requesting a function call. This might happen if the query is simple\n",
    "        # or if the LLM determines it doesn't need the tool.\n",
    "        print(\"\\n--- Gemini decided to answer directly (No Function Call Requested) ---\")\n",
    "        if hasattr(message_part, 'text') and message_part.text is not None:\n",
    "            print(message_part.text)\n",
    "            # Add the direct model response to history\n",
    "            conversation_history.append(model_response_content)\n",
    "        else:\n",
    "            print(\"No text response found in the initial call and no function call made.\")\n",
    "            # Print message part for debugging\n",
    "            # print(f\"Message part was: {message_part}\")\n",
    "        print(\"Stopping execution after direct answer or unexpected initial response.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn unexpected error occurred during the Gemini interaction: {str(e)}\\n{traceback.format_exc()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
