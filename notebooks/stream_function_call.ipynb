{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98f73b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to sign in with email: user@example.com\n",
      "Authentication successful. User ID: 372ec112-6fd7-46a7-bab4-abf7623fb05b\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "     sys.path.insert(0, project_root)\n",
    "\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from supabase import create_client\n",
    "\n",
    "from src.llm.tools.ChunkRetriever import RetrievalService\n",
    "from src.llm.OpenAIClient import OpenAIClient\n",
    "from src.storage.SupabaseService import SupabaseService\n",
    "\n",
    "# ========== Constants and Environment Variables =========\n",
    "YOUR_APP_DOMAIN = \"www.stackifier.com\"\n",
    "TEST_EMAIL = os.environ.get(\"TEST_EMAIL\")\n",
    "TEST_PASSWORD = os.environ.get(\"TEST_PASSWORD\")\n",
    "if not TEST_EMAIL or not TEST_PASSWORD:\n",
    "    raise ValueError(\"TEST_EMAIL and TEST_PASSWORD must be set in your .env file.\")\n",
    "\n",
    "supabase_url = os.environ.get(\"SUPABASE_URL\")\n",
    "supabase_key = os.environ.get(\"SUPABASE_ANON_KEY\")\n",
    "if not supabase_url or not supabase_key:\n",
    "    raise ValueError(\"SUPABASE_URL and SUPABASE_ANON_KEY must be set in your .env file.\")\n",
    "\n",
    "auth_client_local = create_client(supabase_url, supabase_key)\n",
    "\n",
    "print(f\"Attempting to sign in with email: {TEST_EMAIL}\")\n",
    "auth_response = auth_client_local.auth.sign_in_with_password(\n",
    "    {\"email\": TEST_EMAIL, \"password\": TEST_PASSWORD}\n",
    ")\n",
    "if not auth_response or not auth_response.user:\n",
    "    error_detail = auth_response.error.message if hasattr(auth_response, 'error') and auth_response.error else \"Unknown authentication error\"\n",
    "    raise ConnectionError(f\"Supabase authentication failed: {error_detail}. Check credentials and Supabase Auth settings.\")\n",
    "authenticated_user_id_str_local = str(auth_response.user.id)\n",
    "print(f\"Authentication successful. User ID: {authenticated_user_id_str_local}\")\n",
    "\n",
    "user_given_id = authenticated_user_id_str_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5f36cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='Whats 200525.52 * 20.5661614, think carefully, give me the answer in 4 decimal points. use 100 tokens. ')], role='user')]\n",
      "Initializing Gemini client with API key: AIz...yQ\n"
     ]
    }
   ],
   "source": [
    "from src.llm.GeminiClient import GeminiClient\n",
    "from src.llm.tools.FunctionCaller import call_function\n",
    "from src.llm.tools.PythonCalculatorTool import PythonCalculationTool\n",
    "from google.genai import types\n",
    "\n",
    "# Define the function declaration for the model\n",
    "python_calculator_tool_local = PythonCalculationTool()\n",
    "python_calculator_decleration = python_calculator_tool_local.get_tool_declaration_data()\n",
    "\n",
    "# Define the function to execute the Python code\n",
    "execute_python_calculations = python_calculator_tool_local.execute_python_calculations\n",
    "all_tools_functions = [\n",
    "    execute_python_calculations,\n",
    "]\n",
    "\n",
    "# Define the function declaration for the model\n",
    "all_tools_decleration = [\n",
    "    types.Tool(function_declarations=[python_calculator_decleration]),\n",
    "    types.Tool(function_declarations=[RetrievalService.get_tool_declaration()])\n",
    "]\n",
    "\n",
    "config = {\n",
    "    \"tools\": all_tools_decleration,\n",
    "    \"automatic_function_calling\": {\"disable\": True},\n",
    "    \"tool_config\": {\"function_calling_config\": {\"mode\": \"auto\"}},\n",
    "    \"thinking_config\": {\"include_thoughts\": True}\n",
    "}\n",
    "\n",
    "# prompt = \"Show me annual report of tesla in 2021?\" # \"sum first 50 prime numbers, then divide by 0.04215215\"\n",
    "prompt = \"Think first and use the retrieval tool. Whats the Gross Carrying Amount for Total intangible assets for tesla in 2021? then divide the value by 0.04215215\"\n",
    "prompt = \"Whats 200525.52 * 20.5661614, think carefully, give me the answer in 4 decimal points. use 100 tokens. \"\n",
    "CONV_HISTORY = []\n",
    "CONV_HISTORY.append(types.Content(role=\"user\", parts=[types.Part(text=prompt)]))\n",
    "print(CONV_HISTORY)\n",
    "client = GeminiClient(config=config)#, model=\"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb5f665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:`automatic_function_calling.disable` is set to `True`. And `automatic_function_calling.maximum_remote_calls` is a positive number 10. Disabling automatic function calling. If you want to enable automatic function calling, please set `automatic_function_calling.disable` to `False` or leave it unset, and set `automatic_function_calling.maximum_remote_calls` to a positive integer or leave `automatic_function_calling.maximum_remote_calls` unset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Gemini client with API key: AIz...yQ\n",
      "first_rep ][ candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=True, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text=\"**Calculating the Product**\\n\\nI've determined that `execute_python_calculations` is the ideal tool for the user's request. My plan is to execute the multiplication operation and subsequently format the outcome to four decimal places. The resulting value will be stored in `calculation_result`.\\n\\n\\n\")], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=None, finish_reason=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=None, prompt_token_count=650, total_token_count=709) automatic_function_calling_history=None parsed=None\n",
      "first_rep ][ candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=True, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text=\"**Calculating the Product**\\n\\nI've determined that `execute_python_calculations` is the ideal tool for the user's request. My plan is to execute the multiplication operation and subsequently format the outcome to four decimal places. The resulting value will be stored in `calculation_result`.\\n\\n\\n\")], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=None, finish_reason=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] model_version='models/gemini-2.5-flash-preview-05-20' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=None, prompt_token_count=650, total_token_count=709) automatic_function_calling_history=None parsed=None\n",
      "Full streamed response:\n",
      " **Calculating the Product**\n",
      "\n",
      "I've determined that `execute_python_calculations` is the ideal tool for the user's request. My plan is to execute the multiplication operation and subsequently format the outcome to four decimal places. The resulting value will be stored in `calculation_result`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=== single response JSON ===\n",
      "{\n",
      "    \"candidates\": [\n",
      "        {\n",
      "            \"content\": {\n",
      "                \"parts\": [\n",
      "                    {\n",
      "                        \"video_metadata\": null,\n",
      "                        \"thought\": true,\n",
      "                        \"code_execution_result\": null,\n",
      "                        \"executable_code\": null,\n",
      "                        \"file_data\": null,\n",
      "                        \"function_call\": null,\n",
      "                        \"function_response\": null,\n",
      "                        \"inline_data\": null,\n",
      "                        \"text\": \"**Calculating the Product**\\n\\nI've determined that `execute_python_calculations` is the ideal tool for the user's request. My plan is to execute the multiplication operation and subsequently format the outcome to four decimal places. The resulting value will be stored in `calculation_result`.\\n\\n\\n\"\n",
      "                    }\n",
      "                ],\n",
      "                \"role\": \"model\"\n",
      "            },\n",
      "            \"citation_metadata\": null,\n",
      "            \"finish_message\": null,\n",
      "            \"token_count\": null,\n",
      "            \"avg_logprobs\": null,\n",
      "            \"finish_reason\": null,\n",
      "            \"grounding_metadata\": null,\n",
      "            \"index\": 0,\n",
      "            \"logprobs_result\": null,\n",
      "            \"safety_ratings\": null\n",
      "        }\n",
      "    ],\n",
      "    \"model_version\": \"models/gemini-2.5-flash-preview-05-20\",\n",
      "    \"prompt_feedback\": null,\n",
      "    \"usage_metadata\": {\n",
      "        \"cached_content_token_count\": null,\n",
      "        \"candidates_token_count\": null,\n",
      "        \"prompt_token_count\": 650,\n",
      "        \"total_token_count\": 709\n",
      "    },\n",
      "    \"automatic_function_calling_history\": null,\n",
      "    \"parsed\": null\n",
      "}\n",
      "\n",
      "=== content only ===\n",
      "{\n",
      "    \"parts\": [\n",
      "        {\n",
      "            \"video_metadata\": null,\n",
      "            \"thought\": true,\n",
      "            \"code_execution_result\": null,\n",
      "            \"executable_code\": null,\n",
      "            \"file_data\": null,\n",
      "            \"function_call\": null,\n",
      "            \"function_response\": null,\n",
      "            \"inline_data\": null,\n",
      "            \"text\": \"**Calculating the Product**\\n\\nI've determined that `execute_python_calculations` is the ideal tool for the user's request. My plan is to execute the multiplication operation and subsequently format the outcome to four decimal places. The resulting value will be stored in `calculation_result`.\\n\\n\\n\"\n",
      "        }\n",
      "    ],\n",
      "    \"role\": \"model\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# ONLY WORKS WITH NON THIKIN MODEL\n",
    "# Stream the entire response, capture the first chunk for debugging, and collect all text parts\n",
    "texts = []\n",
    "first_resp = None\n",
    "client = GeminiClient(config=config)#, model=\"gemini-2.0-flash\")\n",
    "for chunk in client.generate_content_stream(contents=CONV_HISTORY):\n",
    "    if first_resp is None:\n",
    "        first_resp = chunk\n",
    "    for cand in chunk.candidates:\n",
    "        for part in cand.content.parts:\n",
    "            if part.text:\n",
    "                texts.append(part.text)\n",
    "\n",
    "full_response = \"\".join(texts)\n",
    "print(\"Full streamed response:\\n\", full_response)\n",
    "\n",
    "# 4) inspect the very first chunk\n",
    "if first_resp:\n",
    "    resp_dict = first_resp.model_dump()\n",
    "    if not resp_dict[\"candidates\"][0][\"content\"][\"parts\"][0][\"function_call\"]:\n",
    "        resp_dict[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"] = full_response\n",
    "\n",
    "    print(\"\\n=== single response JSON ===\")\n",
    "    print(json.dumps(resp_dict, indent=4, default=str))\n",
    "\n",
    "    content = resp_dict[\"candidates\"][0][\"content\"]\n",
    "    print(\"\\n=== content only ===\")\n",
    "    print(json.dumps(content, indent=4, default=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671a64e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:`automatic_function_calling.disable` is set to `True`. And `automatic_function_calling.maximum_remote_calls` is a positive number 10. Disabling automatic function calling. If you want to enable automatic function calling, please set `automatic_function_calling.disable` to `False` or leave it unset, and set `automatic_function_calling.maximum_remote_calls` to a positive integer or leave `automatic_function_calling.maximum_remote_calls` unset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thoughts summary:\n",
      "**Performing the Calculation**\n",
      "\n",
      "I've determined that the `execute_python_calculations` tool is the best fit for this task. My current focus is on performing the multiplication and then formatting the output to precisely four decimal places, as requested. I'm aiming for accuracy and efficiency.\n",
      "\n",
      "\n",
      "\n",
      "function: None\n"
     ]
    }
   ],
   "source": [
    "thoughts = \"\"\n",
    "answer = \"\"\n",
    "for chunk in client.generate_content_stream(\n",
    "    contents=prompt,\n",
    "):\n",
    "  for part in chunk.candidates[0].content.parts:\n",
    "    if not part.text:\n",
    "      print(\"function:\", part.text)\n",
    "      continue\n",
    "    elif part.thought:\n",
    "      if not thoughts:\n",
    "        print(\"Thoughts summary:\")\n",
    "      print(part.text)\n",
    "      thoughts += part.text\n",
    "    else:\n",
    "      if not answer:\n",
    "        print(\"Thoughts summary:\")\n",
    "      print(part.text)\n",
    "      answer += part.text\n",
    "    if part.function_call:\n",
    "      print(part.text) # HOW TO GET SECOND PART? The function call?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
