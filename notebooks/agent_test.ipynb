{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "315990f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to sign in with email: user@example.com\n",
      "Authentication successful. User ID: 372ec112-6fd7-46a7-bab4-abf7623fb05b\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "     sys.path.insert(0, project_root)\n",
    "\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from supabase import create_client\n",
    "\n",
    "from src.llm.tools.ChunkRetriever import RetrievalService\n",
    "from src.llm.OpenAIClient import OpenAIClient\n",
    "from src.storage.SupabaseService import SupabaseService\n",
    "\n",
    "# ========== Constants and Environment Variables =========\n",
    "YOUR_APP_DOMAIN = \"www.stackifier.com\"\n",
    "TEST_EMAIL = os.environ.get(\"TEST_EMAIL\")\n",
    "TEST_PASSWORD = os.environ.get(\"TEST_PASSWORD\")\n",
    "if not TEST_EMAIL or not TEST_PASSWORD:\n",
    "    raise ValueError(\"TEST_EMAIL and TEST_PASSWORD must be set in your .env file.\")\n",
    "\n",
    "supabase_url = os.environ.get(\"SUPABASE_URL\")\n",
    "supabase_key = os.environ.get(\"SUPABASE_ANON_KEY\")\n",
    "if not supabase_url or not supabase_key:\n",
    "    raise ValueError(\"SUPABASE_URL and SUPABASE_ANON_KEY must be set in your .env file.\")\n",
    "\n",
    "auth_client_local = create_client(supabase_url, supabase_key)\n",
    "\n",
    "print(f\"Attempting to sign in with email: {TEST_EMAIL}\")\n",
    "auth_response = auth_client_local.auth.sign_in_with_password(\n",
    "    {\"email\": TEST_EMAIL, \"password\": TEST_PASSWORD}\n",
    ")\n",
    "if not auth_response or not auth_response.user:\n",
    "    error_detail = auth_response.error.message if hasattr(auth_response, 'error') and auth_response.error else \"Unknown authentication error\"\n",
    "    raise ConnectionError(f\"Supabase authentication failed: {error_detail}. Check credentials and Supabase Auth settings.\")\n",
    "authenticated_user_id_str_local = str(auth_response.user.id)\n",
    "print(f\"Authentication successful. User ID: {authenticated_user_id_str_local}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aff4cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_service_main = RetrievalService(\n",
    "        openai_client = OpenAIClient(),\n",
    "        supabase_service = SupabaseService(supabase_client=auth_client_local)\n",
    "    )\n",
    "\n",
    "def call_function(function_call, functions):\n",
    "    function_name = function_call.name\n",
    "    function_args = function_call.args\n",
    "    for func in functions:\n",
    "        # 1. Autopick tool\n",
    "        if func.__name__ == function_name:\n",
    "            return func(**function_args)\n",
    "        \n",
    "        # 2. retrieve_financial_chunks tool\n",
    "        if \"retrieve_financial_chunks\" == function_name:\n",
    "            function_result_json = retrieval_service_main.retrieve_chunks(\n",
    "                    user_id=authenticated_user_id_str_local, # Pass user_id explicitly\n",
    "                    **function_args\n",
    "                )\n",
    "            return function_result_json\n",
    "        \n",
    "        # 3. ERROR: Tool not found\n",
    "        if func.__name__ != function_name:\n",
    "            return f\"Function {function_name} not found in the provided functions.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72990c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from src.llm.tools.PythonCalculatorTool import PythonCalculationTool\n",
    "from src.helper.llm_helper_chat import create_final_answer_instructions\n",
    "\n",
    "# Define the function declaration for the model\n",
    "python_calculator_tool_local = PythonCalculationTool()\n",
    "python_calculator_decleration = python_calculator_tool_local.get_tool_declaration_data()\n",
    "\n",
    "# Define the function to execute the Python code\n",
    "execute_python_calculations = python_calculator_tool_local.execute_python_calculations\n",
    "all_tools_functions = [\n",
    "    execute_python_calculations,\n",
    "    \n",
    "]\n",
    "\n",
    "# Define the function declaration for the model\n",
    "all_tools_decleration = [\n",
    "    types.Tool(function_declarations=[python_calculator_decleration]),\n",
    "    types.Tool(function_declarations=[RetrievalService.get_tool_declaration()])\n",
    "]\n",
    "\n",
    "config = {\n",
    "    \"tools\": all_tools_decleration,\n",
    "    \"automatic_function_calling\": {\"disable\": True},\n",
    "    \"tool_config\": {\"function_calling_config\": {\"mode\": \"auto\"}},\n",
    "}\n",
    "\n",
    "# Configure the client\n",
    "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "GEMINI_MODEL = \"gemini-2.0-flash\"\n",
    "chat = client.chats.create(model=GEMINI_MODEL, config=config)\n",
    "# prompt = \"Show me annual report of tesla in 2021?\" # \"sum first 50 prime numbers, then divide by 0.04215215\"\n",
    "prompt = \"Whats the Gross Carrying Amount for Total intangible assets for tesla in 2021? then divide the value by 0.04215215\"\n",
    "\n",
    "CONV_HISTORY = []\n",
    "CONV_HISTORY.append(types.Content(role=\"user\", parts=[types.Part(text=prompt)]))\n",
    "\n",
    "turn_count = 0\n",
    "max_turns = 5\n",
    "while turn_count < max_turns:\n",
    "    turn_count += 1\n",
    "    print(f\"\\n\\n---------------------Iteration count Start : {turn_count}---------------------\\n\\n\")\n",
    "    print(f\"Conversation history before sending to model: {json.dumps([c.to_json_dict() for c in CONV_HISTORY], indent=4)}\")\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=GEMINI_MODEL,\n",
    "        contents=CONV_HISTORY,\n",
    "        config = config,\n",
    "    )\n",
    "    content = response.candidates[0].content\n",
    "    \n",
    "    result = None\n",
    "    \n",
    "    if content.parts[0].function_call:\n",
    "        CONV_HISTORY.append(content)\n",
    "        result = str(call_function(content.parts[0].function_call, all_tools_functions))\n",
    "        function_response_part = types.Part.from_function_response(name=content.parts[0].function_call.name,response={\"output\": result})\n",
    "        CONV_HISTORY.append(types.Content(role=\"user\", parts=[function_response_part]))\n",
    "        final_instructions_text = create_final_answer_instructions(prompt, result, YOUR_APP_DOMAIN)\n",
    "        CONV_HISTORY.append(types.Content(role=\"user\", parts=[types.Part(text=final_instructions_text)]))\n",
    "    else:\n",
    "        if content.parts[0].text:\n",
    "            CONV_HISTORY.append(content)\n",
    "            final_agent_text_response = content.parts[0].text\n",
    "            print(final_agent_text_response)\n",
    "        else:\n",
    "            print(\"(No text in content.parts[0], model might have finished or an issue occurred)\")\n",
    "            final_agent_text_response = \"(Model provided no text in its final turn)\"\n",
    "            print(final_agent_text_response)\n",
    "            break\n",
    "    print(f\"\\n\\n---------------------Iteration count End   : {turn_count}---------------------\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec6876b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import os\n",
    "\n",
    "GEMINI_API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
    "\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "prompt = \"What is the sum of the first 50 prime numbers?\"\n",
    "response = client.models.generate_content(\n",
    "  model=\"gemini-2.5-flash-preview-05-20\",\n",
    "  contents=prompt,\n",
    "  config=types.GenerateContentConfig(\n",
    "    thinking_config=types.ThinkingConfig(\n",
    "      include_thoughts=True\n",
    "    )\n",
    "  )\n",
    ")\n",
    "\n",
    "for part in response.candidates[0].content.parts:\n",
    "  if not part.text:\n",
    "    continue\n",
    "  if part.thought:\n",
    "    print(\"Thought summary:\")\n",
    "    print(part.text)\n",
    "    print()\n",
    "  else:\n",
    "    print(\"Answer:\")\n",
    "    print(part.text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9859458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "print(f\"Response with thought:\\n{json.dumps([c.to_json_dict() for c in response.candidates], indent=4)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c9863e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] Starting run_react_rag test\n",
      "[DEBUG] run_react_rag called with session.user_id=test_user, user_input=Hello RAG test, history_len=0\n",
      "Initialized OpenAI client with model: text-embedding-3-small\n",
      "SupabaseService initialized with provided client.\n",
      "[DEBUG] message received: Hello\n",
      "[TEST] Received chunk: Hello\n",
      "[DEBUG] message received: ! How can I help you today?\n",
      "\n",
      "[TEST] Received chunk: ! How can I help you today?\n",
      "\n",
      "[DEBUG] run_react_rag completed streaming\n",
      "[TEST] run_react_rag test completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from api.v1.dependencies import SUPABASE_KEY, SUPABASE_URL, Session\n",
    "from src.llm.workflow.react_rag import run_react_rag\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "import asyncio\n",
    "# Test run_react_rag function\n",
    "session = Session(user_id='test_user', token=SUPABASE_KEY)\n",
    "test_client = create_client(SUPABASE_URL, SUPABASE_KEY)\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "async def main_test():\n",
    "    print('[TEST] Starting run_react_rag test')\n",
    "    async for chunk in run_react_rag(session, test_client, 'Hello RAG test', []):\n",
    "        print(f'[TEST] Received chunk: {chunk}')\n",
    "    print('[TEST] run_react_rag test completed')\n",
    "asyncio.run(main_test())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
